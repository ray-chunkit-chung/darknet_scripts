{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width_in_cfg_file = 416.\n",
    "height_in_cfg_file = 416.\n",
    "\n",
    "def IOU(x, centroids):\n",
    "    \"\"\" intersection over union\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    k = len(centroids)\n",
    "    for centroid in centroids:\n",
    "        c_w, c_h = centroid\n",
    "        w, h = x\n",
    "        if c_w >= w and c_h >= h:\n",
    "            similarity = w * h / (c_w * c_h)\n",
    "        elif c_w >= w and c_h <= h:\n",
    "            similarity = w * c_h / (w * h + (c_w - w) * c_h)\n",
    "        elif c_w <= w and c_h >= h:\n",
    "            similarity = c_w * h / (w * h + c_w * (c_h - h))\n",
    "        else: #means both w,h are bigger than c_w and c_h respectively\n",
    "            similarity = (c_w * c_h) / (w * h)\n",
    "        similarities.append(similarity) # will become (k,) shape\n",
    "    return np.array(similarities)\n",
    "\n",
    "\n",
    "def avg_IOU(X,centroids):\n",
    "    n,d = X.shape\n",
    "    sum = 0.\n",
    "    for i in range(X.shape[0]):\n",
    "        #note IOU() will return array which contains IoU for each centroid and X[i] // slightly ineffective, but I am too lazy\n",
    "        sum+= max(IOU(X[i],centroids)) \n",
    "    return sum/n\n",
    "\n",
    "\n",
    "def write_anchors_to_file(centroids,X,anchor_file):\n",
    "    f = open(anchor_file,'w')\n",
    "    \n",
    "    anchors = centroids.copy()\n",
    "\n",
    "    for i in range(anchors.shape[0]):\n",
    "        anchors[i][0]*=width_in_cfg_file/32.\n",
    "        anchors[i][1]*=height_in_cfg_file/32.\n",
    "\n",
    "    widths = anchors[:,0]\n",
    "    sorted_indices = np.argsort(widths)\n",
    "\n",
    "    print('Anchors = ', anchors[sorted_indices])\n",
    "        \n",
    "    for i in sorted_indices[:-1]:\n",
    "        f.write('%0.2f,%0.2f, '%(anchors[i,0],anchors[i,1]))\n",
    "\n",
    "    #there should not be comma after last anchor, that's why\n",
    "    f.write('%0.2f,%0.2f\\n'%(anchors[sorted_indices[-1:],0],anchors[sorted_indices[-1:],1]))\n",
    "    \n",
    "    f.write('%f\\n'%(avg_IOU(X,centroids)))\n",
    "    print()\n",
    "\n",
    "    \n",
    "def kmeans(X,centroids,eps,anchor_file):\n",
    "    N = X.shape[0]\n",
    "    iterations = 0\n",
    "    k,dim = centroids.shape\n",
    "    prev_assignments = np.ones(N)*(-1)    \n",
    "    iteration = 0\n",
    "    old_D = np.zeros((N,k))\n",
    "\n",
    "    while True:\n",
    "        D = [] \n",
    "        iteration += 1           \n",
    "        for i in range(N):\n",
    "            d = 1 - IOU(X[i], centroids)\n",
    "            D.append(d)\n",
    "        D = np.array(D) # D.shape = (N,k)\n",
    "        \n",
    "        print(\"iter {}: dists = {}\".format(iteration,np.sum(np.abs(old_D-D))))\n",
    "            \n",
    "        #assign samples to centroids \n",
    "        assignments = np.argmin(D,axis=1)  # assignments shape is N\n",
    "        \n",
    "        if (assignments == prev_assignments).all() :\n",
    "            print(\"Centroids = \",centroids)           \n",
    "            write_anchors_to_file(centroids,X,anchor_file)\n",
    "            return\n",
    "\n",
    "        #calculate new centroids\n",
    "        centroid_sums=np.zeros((k,dim),np.float)\n",
    "        for i in range(N):\n",
    "            centroid_sums[assignments[i]]+=X[i]        \n",
    "        for j in range(k):\n",
    "            centroids[j] = centroid_sums[j]/(np.sum(assignments==j))\n",
    "        \n",
    "        prev_assignments = assignments.copy()     \n",
    "        old_D = D.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1: dists = 43.38348313998492\n",
      "iter 2: dists = 3.208040763680277\n",
      "iter 3: dists = 1.4467973205071707\n",
      "iter 4: dists = 1.2595827121477354\n",
      "iter 5: dists = 0.7616529709335693\n",
      "iter 6: dists = 0.7964806104079969\n",
      "iter 7: dists = 0.9021189805007712\n",
      "iter 8: dists = 0.311434288526269\n",
      "iter 9: dists = 0.6397421200427144\n",
      "Centroids =  [[ 0.67669206  0.67680459]\n",
      " [ 0.7569162   0.75712671]\n",
      " [ 0.69275869  0.6928935 ]\n",
      " [ 0.73028852  0.7307415 ]\n",
      " [ 0.71164821  0.71179706]]\n",
      "Anchors =  [[ 8.79699674  8.79845962]\n",
      " [ 9.00586293  9.00761556]\n",
      " [ 9.25142672  9.25336178]\n",
      " [ 9.49375075  9.49963947]\n",
      " [ 9.83991054  9.84264725]]\n",
      "\n",
      "centroids.shape (5, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "pwd = os.getcwd()\n",
    "output_dir = os.path.join(pwd, 'anchor')\n",
    "filelist = os.path.join(pwd, 'train_list.txt')\n",
    "anchor_file = os.path.join(output_dir, 'anchors{}.txt'.format(num_clusters))\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "with open(filelist) as f:\n",
    "    lines = [line.rstrip('\\n') for line in f.readlines()]\n",
    "\n",
    "# a list of bbox normalized w, h\n",
    "annotation_dims = []\n",
    "for line in lines:\n",
    "    with open(line.replace('.jpg','.txt')) as f2:\n",
    "        for line in f2.readlines():\n",
    "            w, h = line.rstrip('\\n').split(' ')[3:]\n",
    "            annotation_dims.append([w, h])\n",
    "annotation_dims = np.array(annotation_dims).astype(float)\n",
    "\n",
    "# randomly pick initial cluster centroids\n",
    "indices = np.random.randint(len(annotation_dims), size=num_clusters)\n",
    "centroids = annotation_dims[indices]\n",
    "eps = 0.005\n",
    "\n",
    "# kmeans with standard expection-maximization; distance metrics is customized\n",
    "kmeans(annotation_dims, centroids, eps, anchor_file)\n",
    "\n",
    "print('centroids.shape', centroids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
